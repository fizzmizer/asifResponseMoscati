\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[english]{babel}
\usepackage{geometry}
%\usepackage{cite}
\usepackage{mathrsfs}
\usepackage{tikz-cd}
\usetikzlibrary{arrows}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{array}
\usepackage{lscape}
\usepackage{longtable}
\usepackage{multirow}
\usepackage[strict]{changepage}
\usepackage{authblk}
\usepackage{csquotes}
\usepackage{caption}
\captionsetup[figure]{font=scriptsize}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\title{As-if models and scientific realism: a response to Moscati}
\date{}
\author[1]{Antoine Brandelet}
\author[1,2]{Jeremy Attard}

\affil[1]{Department of Philosophy and History of Science, University of Mons, Belgium}
\affil[2]{Department of Sciences, Philosophies and Societies, University of Namur, Belgium}

\begin{document}
\maketitle

\begin{abstract}
    In a recent paper, Moscati provides an analysis of as-if modelling in economics, more precisely in decision theory. According to him, most of decision theoretical models---be it neoclassical, behavioural or heuristic---are as-if, and that should be no worry at all. That observation is then taken to be a reason to move forward a realist understanding of modelling and embrace a form of instrumentalism.

    Here, we wish to support Moscati's claim of the positive epistemic value of as-if modelling while keeping a realist interpretation. We show that the core of the instrumentalist critique he provides is based on a misunderstanding of the very mechanism of as-if modelling. We then propose a realist framework in which the variety of modelling strategies, in economics as well as in physics, can be described.
\end{abstract}


\section{Introduction}

In a recent paper \citep{Moscati2023}, 

Moscati first distinguishes three classes of models in decision theory: neo-classical, behavioral and heuristic. The major representative of the first class is rational choice theory, or expected utility theory, in which agents are assumed to attach a utility value (a real number) to each outcome of possible risky choices, and to make the choice which maximizes the expected utility. The second class contains attempts to improve neo-classical models by various means, including more complex assumptions about the form of utility function or accounting for biased perceived probabilities of different outcomes by the decision makers. The third class also aims at amending neo-classical models but unlike the two first ones does not assume that agents maximize anything, but only that they make choices among a finite set of possibilities following some heuristic (simple) rules. Behavioral and heuristic models historically developed in reaction to epistemological criticisms addressed to neo-classical models. The most salient is the lack of realisticness of their basic assumptions due to the accumulating amount of evidence that these basic assumptions seem to be systematically violated in decision theory experiments. That is to say, the first class of models was originally criticized for it seems to commit to an instrumentalist philosophical position known as the ``as-if'' account of models in economics, mainstream in this field from the seminal work of Milton Friedman \cite{Friedman1953}. Moscati gives the following definition of the as-if account of modeling in decision theory \citep[p. 2]{Moscati2023}: 

\begin{quote}
    Broadly speaking, as-if models attempt to account for the observable choices that individuals make, but do not pretend to capture the underlying psychological mechanisms that might generate those choices. Some underlying choice-generating mechanism, such as utility maximization, is attached to the model. However, in the as-if approach the decision theorist is agnostic about whether this mechanism actually operates in the mind of the decision maker. She may even deem, and explicitly acknowledge, that the posited mechanism and its components (such as the utility function, the preference relation or the heuristic rules), are only fictional constructs. Nonetheless, the decision theorist explains, describes or predicts the decision maker’s choices as if they were generated by the posited psychological mechanism at issue. Insofar as the as-if model is capable of accounting for the decision maker’s choice behaviour or indicating ways to effectively control it for economic policy purposes, the model is considered scientifically valid.
\end{quote}

The two other classes of models are made to be more acceptable from an epistemological viewpoint for they rest on human behaviour's assumptions which correspond more to what is otherwise observed in experiments.

In his paper, Moscati defends two main positions: 1/ \textit{all} decision theory models, including behavioral and heuristic ones, are as-if models -- whatever they claim to be; 2/ there is \textit{no worry} at all with this situation, as long as it is seen within the right antirealist framework. According to him, the latter goes beyond traditional instrumentalism, as explanation is considered a genuine and important aim of science. %Moscati only argues, resting e.g. on Alisa Bokulich's work about model explanations \citep{Bokulich2009}, that it is possible to defend a (mechanism-based) view of explanation without being committed to any form of realism going beyond ontological realism. 


Our paper is structured as follows. In Section \ref{sec:realisticness}, we first clarify the discussion by distinguishing between “realisticness” of basic assumptions, in the sense of being compatible or coherent with what is otherwise known, and “realism” of theories’ contents, in the philosophical sense of scientific realism. We argue that this distinction is relevant precisely because the question of scientific realism takes on its full meaning in the cases we cannot know directly whether these assumptions are true and whether the entities to which they refer actually exist. We then take some examples in physics to argue that requiring realisticness of basic assumptions is too strong and demanding a criterion which is not even reached in physics, contrary to what is sometimes claimed, without a priori impinging on the acceptability or scientificity of physical models. This observation ties in with the more general fictional view of models, presented in section \ref{sec:asifVerifJust}. [Décrire en une phrase de quoi il s’agit] This nevertheless raises two important questions: 1/ can we build an epistemological criterion of model selection escaping mere relativism without demanding realisticness of basic assumptions? (epistemological question) 2/ accepting that unrealistic assumptions still play an important cognitive role in scientific inquiry do condemn us to any form of antirealism? (realism-related question). In this paper we address these questions alternatively. In section \ref{sec:epistemo_criterion} we develop an epistemological criterion encompassing the observations previously made. In section \ref{sec:asif_realism} we then argue that embracing the fictional view of models does not force us to any form of antirealism. On the contrary, we build a realist framework compatible with a fictional view of models. Moreover, we show that the answers we provide to both the epistemological and the realism-related questions actually strengthen each other.


%Our paper is structured as follows. In Section \ref{sec:realisticness}, we critique one of the basic propositions Moscati takes to be the sign of a need to go beyond a realist of economical models, i.e. the observation that models often assign to agents capabilities or properties that are incompatible with psychological background knowledge. If we can accept that models feature idealisations and deliberate falsities, we argue that 1/ it should not be understood as a divergence from scientific realism because 2/ the condition of realistic hypotheses in models---i.e. compatible with background knowledge--- is never met in science, even in physics.

%Section \ref{sec:asifVerifJust} follows Moscati's claim of the omnipresence and harmlessness of as-if modelling while arguing for the possibility of keeping an

\section{What does it mean to have ``realistic'' assumptions?}
\label{sec:realisticness}
%\subsection{Assumptions' realisticness and theories' realism}
Basic assumptions of decision theory models are thus often criticized for their lack of realism, which is seen as a fundamental epistemological drawback. Yet, there are two different - although related - philosophical discussions at play here, which are sometimes confused and that we would like to distinguish. Indeed, when scholars talk about the ``realisticness'' of basic assumptions in such models, they often mean their \textit{consistency} with what is otherwise known -- about human behavior, for instance. Consistency of basic assumptions with what is otherwise known is an epistemological demand -- that is, a criterion of acceptability or justification of a good scientific model. However, this ``realisticness'' of hypotheses should not be strictly confused with ``realism'' in the sense of \textit{scientific realism}. As Moscati points out in his paper, the latter is a philosophical framework of interpretation of the content of scientific theories, in their ontological, semantic or epistemic aspects, and in relation to their empirical success. 

Discussions about scientific realism are particularly focused on hypotheses bearing on entities which are \textit{not} observable but still play an important role, e.g. in the explanation of the phenomenon studied. The distinction between realisticness and realism is thus quite relevant in this case. Indeed, it is precisely because we cannot know directly whether these hypotheses are true (and whether the entities to which they refer actually exist) that the question of realism (semantic and epistemic in particular) takes on its full meaning. Moreover, in the case these assumptions can be assessed and are shown to be false, or more precisely inconsistent with some background knowledge, this distinction allows to ask the question of how knowingly false assumptions can still play an important cognitive role in scientific inquiry. This question is actually relevant because in a lot of cases, models which are fully acknowledged as being of high reliability and scientificity, e.g. in physics, do rest on such not-only-idealized-but-false assumptions. We now argue that the comparison with these physics’ examples suggests that realisticness does not seem to be a necessary criterion of acceptability.

%\subsection{Coherence of basic assumptions is not a necessary epistemological criterion}
Lack of realisticness of basic assumptions in theoretical models in physics has at least three dimensions that we would like to highlight here. First, some basic assumptions are not testable independently of the very theoretical framework within which they are used. Indeed, on the one hand, fundamental principles as Newtonian law of motion cannot be tested per se, but only through the specification of some auxiliary hypotheses -- here, the specification of types of forces or energy which are assumed to be at play in the phenomena studied. On the other hand, these specific hypotheses cannot be independently tested neither. Take the fact that kinetic energy $E_k$ of a particle of mass $m$ and speed $v$ reads: 
\begin{equation}
E_k=\frac{1}{2}mv^2.
\label{eq:kinetic-energy}
\end{equation}

Hypothesis \eqref{eq:kinetic-energy} does not have any meaning outside Newtonian mechanics, and more precisely without a general law about how energy of physical systems described by Newtonian mechanics behaves. Then, when hypothesis \eqref{eq:kinetic-energy} is used in a physical model, it is not justified by its mere independent truth, but only because the whole system:

\begin{equation}
\{\mathrm{fundamental~principles + specific~hypotheses}\}
\label{eq:pattern_expl}
\end{equation}

gives rise to a model which produces falsifiable and empirically adequate predictions.

Second, some basic assumptions can be tested independently of the model at play -- however, they can still be considered as good and justified hypotheses even when they turn out to be wrong, i.e. refuted by independent investigations. Take as an example the kinetic theory of gas. Ideal gas law: $PV=nRT$ can be derived from microscopic considerations, modelling the gas as a set of $N\approx 10^{23}$ identical particles (material points of mass $m$) confined in a volume $V$. The particles are assumed to interact only with the walls of the box they are confined in via elastic shocks, and not between them. These basic assumptions are false at two levels here, and still the model they take part allows for a computation of the ideal gas law which is considered as a genuine explanation. On the one hand, if we consider that the gas is constituted of material particles, then at temperature under consideration they probably experience \textit{millions} of shocks per second. Thus, the absence of interaction between particles is not a mere approximation but a knowingly false assumption. On the other hand, we know from more fundamental theoretical framework as quantum mechanics that the gas molecules are \textit{not} mere material points or particles but more complicated objects as wave functions only giving information about probabilities of different states in which the system can be.

Finally, as it is presented e.g. in \citep{Suppe2000} as an argument against some logical empiricists' positions, a given physical theory can usually be formulated in several distinct ways such that these formulations, even if theoretically and empirically equivalent, postulate \textit{different} entities or mechanisms. A well-known example is Newtonian mechanics, which can be formulated postulating either a set of forces modifying the trajectory on material points, a Lagrangian associated to the material point such that the latter follows the trajectory which minimizes the integral of the Lagrangian along the trajectory or a Hamiltonian driving the dynamics of the physical system seen as a point in a phase space, according to Hamilton equations. More specifically, classical \textit{gravity} can be formulated in the Newtonian framework by postulating well-known $1/r^2-$gravitational force, but can also be formulated in the Newton-Cartan geometrical framework without postulating forces but rather describing it as the manifestation of the curvature of an underlying (classical) spacetime \citep[Chapter~1]{Ehlers1973}. This is not a specificity of Newtonian mechanics, but a feature shared by all physical theories. For instance, quantum mechanics acknowledges at least nine different formulations \citep{Styer2002}: Heisenberg's (matrix), Schrödinger's (wavefunction), Feynman's (path integral), Wigner's (phase space), density matrix, second quantization, variational, de Broglie-Bohm's (pilot wave) and Hamilton-Jacobi's. As for General Relativity, it can also be formulated different ways \citep{Goeckeler2011, Krasnov2020, Arnowitt2008}: using tensor calculus on differential manifolds, Cartan geometry on principal fiber bundles, encoding gravitation in torsion instead of in curvature, or deriving fields equations from Lagrangian or even Hamiltonian principles. All these formulations are equivalent in the sense that it is perfectly known how to mathematically pass from one to the other, and have the same empirical success. However, entities that they postulate (forces or Lagrangians, quantum states as vectors or density matrix, spacetime torsion or curvature, and so on) together with fundamental mechanisms and laws which lie at the foundation of their explanatory power have sometimes nothing to do with each other. Picture of reality given by these formulations are thus deeply distinct, even though the latter are epistemologically equivalent and all highly acceptable as explanatory models. 

This observation then highly \textit{suggests} that realisticness of basic hypotheses is finally neither necessary nor relevant a criterion as for the acceptability of theoretical models. This very statement actually ties in with the more general \textit{fictional view} of models, presented in section~\ref{sec:asifVerifJust}. As already written in the introduction, this view nevertheless raises two important questions: an epistemological one (how to justify the use of models if the realisticness of their basic assumptions is not necessary?) and a realism-related one (do such a view condemn us to antirealism?). We tackle these issues in section~\ref{sec:epistemo_criterion} and in section~\ref{sec:asif_realism} respectively.

\section{As-if modelling and reference}
\label{sec:asifVerifJust}

\subsection{Models are fictions, and that's no worry at all}

The central tension at play may be called the \textit{modelling conundrum} and can be stated as follows:

\begin{definition}[Modelling Conundrum (MC)]
    Scientific models play a central role in representing and explaining, and yet they feature idealisations and deliberate falsities.
\end{definition}

MC if often taken as a basis of a critique of truth-oriented positions in various sectors of epistemology and philosophy of science. An obvious example is \textit{naïve scientific realism}: if an empirically adequate and predictively powerful model is interpreted as a faithful description of a phenomenon, then how is it possible to account for its idealised characteristics?

There is therefore a close relationship between the emphasis placed on the ``as-if'' nature of models and antirealist or even instrumentalist conceptions of science. Idealisations, simplifications, abstractions or even the introduction of purely fictional entities or mechanisms, possess obvious epistemic virtues (citer des trucs sur les vertus de l'idéalisation, khalifa etc.): simplicity, computability, etc.

As we showed earlier, the conundrum has less to do with the realisticness of the model's basic assumptions than with the interpretation of its empirical and predictive power. Even in physics, models feature this kind of false, or incompatible with background knowledge, assumptions.\footnote{For example, the billiard ball model of gases describes entities that simply cannot exist in a quantum universe.}

If Moscati's first assumption about ``as-ifness'' of models is inaccurate, we can still make sense of the core of his argument: the as-if nature of modelling is problematic for truth-oriented conceptions of scientific succes.

The problem can now be framed in more specific terms: is it possible to accept Moscati's second claim, namely that as-ifness is not problematic, while resisting antirealist or instrumentalist tendencies? We think the response is positive and the remainder of this paper is intended to defend this claim.

MC is particularly noticeable when adopting the so-called ``fiction-view of models''. In this perspective, models are conceives as props in a game of make-believe: an agent using a model of some target system, be it physical, social or economical, is engaging in a game of make-believe by accepting a set of hypotheses for the sake of manipulating the model, i.e. deriving new fictional propositions (propositions true inside the fiction) from known ones.

This framework is interesting because it makes clear the distinction between what is true inside the model and what is possibly true outside, i.e. in what the model portrays. Engaging in a game of make-believe involves accepting some knowingly false assumptions only for the sake of the game: no ontological weight is attached to them.

That explains the coexistence of incompatible hypotheses or models, as in the case of semi-classical models in physics. A physicist manipulating the billiard ball model in order to work out the temperature or pressur of a perfect gas using the well-known equation $PV=nRT$ is not committed to the claim that molecules bounce off each other.

Therefore, we see that the critique of economical as-if models as faithful representations of target systems and mechanisms rely on a inaccurate understanding of the status of idealisations and knowingly false assumptions in modelling. The latter have epistemic virtues and explanatory power (see Section \ref{sec:expla} hereunder for a further discussion of the explanatory power of fictional models), but they do not reduce the models as predictive tools. (faut avoir dit avant qu'il existe un moyen de justifier ces modèles as-if. Putain, Antoine, tu structures aux fraises, là)

Regarding as-if modelling, and keeping in mind the content of MC, we can now better understand Moscati's proposal of being agnostic about ``whether this mechanism actually operates in the mind of the decision maker''. \citep[p.~2]{Moscati2023}

This attitude is exactly what the make-believe view of modelling puts forward: an agent might want to use the assumption that such and such mechanism operates in the mind of the decision maker while not believing id does, just as a reader might engage in a novel without believing a school of magic does exist. All the reasons we have to believe that these assumptions are not realistic (because they are not compatible with what is known of human psychology, for example) do not change anything to the kind of game the modeller is playing when using the model. Trying to save the realisticness of these hypotheses by assuming they are not conscious in the mind of the decision maker simply shifts the problem. As Moscati puts himself about these model-mechanisms: '' it is more appropriate to acknowledge that they take place in the conscious mind of the decision theorist.'' \citep[p.~12]{Moscati2023}


\subsection{Fictions, reference and justification}

As we have seen, the realist challenge is not about interpreting psychologically the functions that appear in the economical models. With this regard, they are perfectly acceptable as they are: fictional statements true only in the model.

The realist challenge rather concerns the possibility of establishing independent means of justification of the model. To understand the very nature of the problem, let us take a closer look at Moscati's flavour of antirealism. As he defines it \citep[pp.~18-20]{Moscati2023}, following the three-fold definition of \citep{Psillos1999}, he:

\begin{itemize}
    \item Accepts the metaphysical thesis according to which there is a mind-independent reality which is the object of scientific inquiry
    \item Accepts the semantic thesis about observable, but remains sceptical about unobservable (expliquer ce que ça veut dire plus en détail parce que je pense qu'on a un point de désaccord là-dessus. Faut qu'on en parle)
    \item Accepts the epistemological thesis about observables, models are true descriptions of the observable, while being sceptical about unobservable entities and mechanism that produce the observed behaviour.
\end{itemize}


\section{``Unrealistic'' assumptions as substrates of modeling and classification principles}
\label{sec:epistemo_criterion}
From a fictional view of modelling developed in section~\ref{sec:asifVerifJust}, it turns out that some basic assumptions does not have to be taken too literally, as really describing what is going on beyond direct observations, but as mere \textit{substrates of modelling}. That is to say, as hypotheses which are necessary to take but which are not genuine empirical statements. Take a metro map as an illustrative example. A metro map can be seen as a model of the real metro system, a lot of features of which are highly idealized or even literally wrong, as the form of the lines between metro stations. However, if the purpose is to be able to move from a station to another one, it would be silly not to trust such a map for the reason that it contains idealizations or ``false assumptions'' about the form of the lines between stations. Our point is not that empirical false statements do not matter in general, but rather that these assumptions \textit{are not empirical statements}. The form of the lines between stations has to be represented in some ways for the map to exist, but they are not claiming anything about the lines between stations as they really are out there. Indeed, this is simply not the purpose of the map and it is assumed that the form of the lines does not impinge on this purpose. Likewise metro lines have to be represented having a certain form (for instance, as straight lines), agents in rational choice, behavioral or heuristic models have to be represented computing information in some way in order to reproduce the observed behaviors. However, there is no reason for this representation to be realistic, i.e. consistent with what is otherwise known about human behavior, as long as the model reaches the purpose for which it is built. 

We thus agree with Moscati on the point that any model (in general, but in particular in decision theory) is as-if, and that it is not a fundamental epistemological issue. As for the epistemological criteria of acceptability of a given model, from the antirealist perspective of Moscati  \citep[p.~22]{Moscati2023}: 

\begin{quote}
Insofar as a decision mechanism produces, i.e. explains, the targeted choice-behaviour phenomena in a simple and parcimonious way, and insofar as the decision theory incorporating the mechanism is successful \textelp{} in describing, predicting or controlling the targeted choice-behaviour phenomena, the explanation provided by the mechanism is a valid one.'' 
\end{quote}

We obviously agree that classical epistemological criteria as simplicity, parsimony or predictive capacity are good criteria in general and in the case of mechanisms-based explanations in particular. However, we would like to go a bit further and build up a an epistemological criterion dealing explicitly with the issue of false assumptions in the modelling process and possibly realist-compatible. We now introduce this ``structural invariance'' criterion, as developed by one author in more details in \citep{attard_rationality}. Later on, it will be argued that this criterion is able to take into account all features of as-if modelling issues as described above while possibly being justified from a realist perspective.

The construction of the criterion rests on the following observation: the non triviality of an explanation of the form $\{\mathrm{fundamental~principles + specific~hypotheses}\}$ as described above in equation \eqref{eq:pattern_expl} rests on the constraints which are imposed to the set of specific hypotheses used in a given empirical context. More precisely, if acting rationally only means maximizing a utility function, then given any behavior, it is always possible to find a utility function to maximize, under the form of \textit{ad hoc} hypotheses. Besides, this is a classical criticism of the (wild) use of rationality in the social science, as expressed e.g. in \citep[p.~498]{Hedstroem2021}:
\begin{quote}
What Becker and his followers showed is that it is possible to come up with coherent rational narratives that fit even the most puzzling and seemingly irrational kinds of behavior, particularly if the narratives are free to ignore known empirical facts about the behavior of individuals.
\end{quote}

Thus, relevant epistemological criteria do not apply directly to the fundamental principles or the specific hypotheses \textit{per se}, e.g. demanding their accuracy, realisticness or external consistency, but rather to the set of constraints which are imposed to the specific hypotheses in order to turn \eqref{eq:pattern_expl} into a non trivial explanation within a given set of fundamental principles. In physics, what makes a specific hypothesis (for example, gravitational term in Newtonian physics: $\mathbf{F}=-\frac{GmM}{r^2}\mathbf{e_r}$) epistemologically acceptable is not that it is realistic or merely true (for reasons cited above), but rather that it is \textit{systematically} associated to a certain set of empirical situations (here, some gravitational phenomena) with great empirical success (non trivial adequacy), and that in other formulations of classical mechanics it has a corresponding term which is also systematically associated to the same set of empirical situations with the same empirical success. Thus, the constraints imposed to the set of acceptable theoretical hypotheses ends up exhibiting a certain \textit{structure}: a systematic association between classes of phenomena and classes of models which explain them. The final point is that even if general principles and theoretical hypotheses can be formulated in different ways, they provide isomorphic classifications of models and thus a classification of phenomena which does not depend on any particular formulation. 


We argue that this observation is not restricted to physis and is rather a fundamental epistemological feature +++ construire la map T et énoncer le principe d'invariance structurelle. 


\section{As-if modeling, justification and realism}
\label{sec:asif_realism}
\section{Realism and explanation veritism}

\section{Conclusion}

\bibliography{biblio} 
\bibliographystyle{plainnat}
\end{document}
