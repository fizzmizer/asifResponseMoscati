\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[english]{babel}
\usepackage{geometry}
%\usepackage{cite}
\usepackage{mathrsfs}
\usepackage{tikz-cd}
\usetikzlibrary{arrows}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{array}
\usepackage{lscape}
\usepackage{longtable}
\usepackage{multirow}
\usepackage[strict]{changepage}
\usepackage{authblk}
\usepackage{csquotes}
\usepackage{caption}
\captionsetup[figure]{font=scriptsize}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\title{As-if models and scientific realism: a response to Moscati}
\date{}
\author[1]{Antoine Brandelet}
\author[1,2]{Jeremy Attard}

\affil[1]{Department of Philosophy and History of Science, University of Mons, Belgium}
\affil[2]{Department of Sciences, Philosophies and Societies, University of Namur, Belgium}

\begin{document}
\maketitle

\begin{abstract}
    In a recent paper, Moscati provides an analysis of as-if modelling in economics, more precisely in decision theory. According to him, most of decision theoretical models---be it neoclassical, behavioural or heuristic---are as-if, and that should be no worry at all. That observation is then taken to be a reason to move forward a realist understanding of modelling and embrace a form of instrumentalism.

    Here, we wish to support Moscati's claim of the positive epistemic value of as-if modelling while keeping a realist interpretation. We show that the core of the instrumentalist critique he provides is based on a misunderstanding of the very mechanism of as-if modelling. We then propose a realist framework in which the variety of modelling strategies, in economics as well as in physics, can be described.
\end{abstract}


\section{Introduction}

In a recent paper \citep{Moscati2023}, 

Moscati first distinguishes three classes of models in decision theory: neo-classical, behavioral and heuristic. The major representative of the first class is rational choice theory, or expected utility theory, in which agents are assumed to attach a utility value (a real number) to each outcome of possible risky choices, and to make the choice which maximizes the expected utility. The second class contains attempts to improve neo-classical models by various means, including more complex assumptions about the form of utility function or accounting for biased perceived probabilities of different outcomes by the decision makers. The third class also aims at amending neo-classical models but unlike the two first ones does not assume that agents maximize anything, but only that they make choices among a finite set of possibilities following some heuristic (simple) rules. Behavioral and heuristic models historically developed in reaction to epistemological criticisms addressed to neo-classical models. The most salient is the lack of realisticness of their basic assumptions due to the accumulating amount of evidence that these basic assumptions seem to be systematically violated in decision theory experiments. That is to say, the first class of models was originally criticized for it seems to commit to an instrumentalist philosophical position known as the ``as-if'' account of models in economics, mainstream in this field from the seminal work of Milton Friedman \cite{Friedman1953}. Moscati gives the following definition of the as-if account of modelling in decision theory \citep[p. 2]{Moscati2023}: 

\begin{quote}
    Broadly speaking, as-if models attempt to account for the observable choices that individuals make, but do not pretend to capture the underlying psychological mechanisms that might generate those choices. Some underlying choice-generating mechanism, such as utility maximization, is attached to the model. However, in the as-if approach the decision theorist is agnostic about whether this mechanism actually operates in the mind of the decision maker. She may even deem, and explicitly acknowledge, that the posited mechanism and its components (such as the utility function, the preference relation or the heuristic rules), are only fictional constructs. Nonetheless, the decision theorist explains, describes or predicts the decision maker’s choices as if they were generated by the posited psychological mechanism at issue. Insofar as the as-if model is capable of accounting for the decision maker’s choice behaviour or indicating ways to effectively control it for economic policy purposes, the model is considered scientifically valid.
\end{quote}

The two other classes of models are made to be more acceptable from an epistemological viewpoint for they rest on human behaviour's assumptions which correspond more to what is otherwise observed in experiments.

In his paper, Moscati defends two main positions: 1/ \textit{all} decision theory models, including behavioral and heuristic ones, are as-if models -- whatever they claim to be; 2/ there is \textit{no worry} at all with this situation, as long as it is seen within the right antirealist framework. According to him, the latter goes beyond traditional instrumentalism, as explanation is considered a genuine and important aim of science. %Moscati only argues, resting e.g. on Alisa Bokulich's work about model explanations \citep{Bokulich2009}, that it is possible to defend a (mechanism-based) view of explanation without being committed to any form of realism going beyond ontological realism. 


Our paper is structured as follows. In Section \ref{sec:realisticness}, we first clarify the discussion by distinguishing between “realisticness” of basic assumptions, in the sense of being compatible or coherent with what is otherwise known, and “realism” of theories’ contents, in the philosophical sense of scientific realism. We argue that this distinction is relevant precisely because the question of scientific realism takes on its full meaning in the cases we cannot know directly whether these assumptions are true and whether the entities to which they refer actually exist. We then take some examples in physics to argue that requiring realisticness of basic assumptions is too strong and demanding a criterion which is not even reached in physics, contrary to what is sometimes claimed, without a priori impinging on the acceptability or scientificity of physical models. This observation ties in with the more general fictional view of models, presented in section \ref{sec:asifVerifJust}. [Décrire en une phrase de quoi il s’agit] This nevertheless raises two important questions: 1/ can we build an epistemological criterion of model selection escaping mere relativism without demanding realisticness of basic assumptions? (epistemological question) 2/ accepting that unrealistic assumptions still play an important cognitive role in scientific inquiry do condemn us to any form of antirealism? (realism-related question). In this paper we address these questions alternatively. In section \ref{sec:epistemo_criterion} we develop an epistemological criterion encompassing the observations previously made. In section \ref{sec:asif_realism} we then argue that embracing the fictional view of models does not force us to any form of antirealism. On the contrary, we build a realist framework compatible with a fictional view of models. Moreover, we show that the answers we provide to both the epistemological and the realism-related questions actually strengthen each other.


%Our paper is structured as follows. In Section \ref{sec:realisticness}, we critique one of the basic propositions Moscati takes to be the sign of a need to go beyond a realist of economical models, i.e. the observation that models often assign to agents capabilities or properties that are incompatible with psychological background knowledge. If we can accept that models feature idealisations and deliberate falsities, we argue that 1/ it should not be understood as a divergence from scientific realism because 2/ the condition of realistic hypotheses in models---i.e. compatible with background knowledge--- is never met in science, even in physics.

%Section \ref{sec:asifVerifJust} follows Moscati's claim of the omnipresence and harmlessness of as-if modelling while arguing for the possibility of keeping an

\section{What does it mean to have ``realistic'' assumptions?}
\label{sec:realisticness}
%\subsection{Assumptions' realisticness and theories' realism}
Basic assumptions of decision theory models are thus often criticized for their lack of realism, which is seen as a fundamental epistemological drawback. Yet, there are two different - although related - philosophical discussions at play here, which are sometimes confused and that we would like to distinguish. Indeed, when scholars talk about the ``realisticness'' of basic assumptions in such models, they often mean their \textit{consistency} with what is otherwise known -- about human behavior, for instance. Consistency of basic assumptions with what is otherwise known is an epistemological demand -- that is, a criterion of acceptability or justification of a good scientific model. However, this ``realisticness'' of hypotheses should not be strictly confused with ``realism'' in the sense of \textit{scientific realism}. As Moscati points out in his paper, the latter is a philosophical framework of interpretation of the content of scientific theories, in their ontological, semantic or epistemic aspects, and in relation to their empirical success. 

Discussions about scientific realism are particularly focused on hypotheses bearing on entities which are \textit{not} observable but still play an important role, e.g. in the explanation of the phenomenon studied. The distinction between realisticness and realism is thus quite relevant in this case. Indeed, it is precisely because we cannot know directly whether these hypotheses are true (and whether the entities to which they refer actually exist) that the question of realism (semantic and epistemic in particular) takes on its full meaning. Moreover, in the case these assumptions can be assessed and are shown to be false, or more precisely inconsistent with some background knowledge, this distinction allows to ask the question of how knowingly false assumptions can still play an important cognitive role in scientific inquiry. This question is actually relevant because in a lot of cases, models which are fully acknowledged as being of high reliability and scientificity, e.g. in physics, do rest on such not-only-idealized-but-false assumptions. We now argue that the comparison with these physics’ examples suggests that realisticness does not seem to be a necessary criterion of acceptability.

%\subsection{Coherence of basic assumptions is not a necessary epistemological criterion}
Lack of realisticness of basic assumptions in theoretical models in physics has at least three dimensions that we would like to highlight here. First, some basic assumptions are not testable independently of the very theoretical framework within which they are used. Indeed, on the one hand, fundamental principles as Newtonian law of motion cannot be tested per se, but only through the specification of some auxiliary hypotheses -- here, the specification of types of forces or energy which are assumed to be at play in the phenomena studied. On the other hand, these specific hypotheses cannot be independently tested neither. Take the fact that kinetic energy $E_k$ of a particle of mass $m$ and speed $v$ reads: 
\begin{equation}
E_k=\frac{1}{2}mv^2.
\label{eq:kinetic-energy}
\end{equation}

Hypothesis \eqref{eq:kinetic-energy} does not have any meaning outside Newtonian mechanics, and more precisely without a general law about how energy of physical systems described by Newtonian mechanics behaves. Then, when hypothesis \eqref{eq:kinetic-energy} is used in a physical model, it is not justified by its mere independent truth, but only because the whole system:

\begin{equation}
\{\mathrm{fundamental~principles + specific~hypotheses}\}
\label{eq:pattern_expl}
\end{equation}

gives rise to a model which produces falsifiable and empirically adequate predictions.

Second, some basic assumptions can be tested independently of the model at play -- however, they can still be considered as good and justified hypotheses even when they turn out to be wrong, i.e. refuted by independent investigations. Take as an example the kinetic theory of gas. Ideal gas law: $PV=nRT$ can be derived from microscopic considerations, modelling the gas as a set of $N\approx 10^{23}$ identical particles (material points of mass $m$) confined in a volume $V$. The particles are assumed to interact only with the walls of the box they are confined in via elastic shocks, and not between them. These basic assumptions are false at two levels here, and still the model they take part allows for a computation of the ideal gas law which is considered as a genuine explanation. On the one hand, if we consider that the gas is constituted of material particles, then at temperature under consideration they probably experience \textit{millions} of shocks per second. Thus, the absence of interaction between particles is not a mere approximation but a knowingly false assumption. On the other hand, we know from more fundamental theoretical framework as quantum mechanics that the gas molecules are \textit{not} mere material points or particles but more complicated objects as wave functions only giving information about probabilities of different states in which the system can be.

Finally, as it is presented e.g. in \citep{Suppe2000} as an argument against some logical empiricists' positions, a given physical theory can usually be formulated in several distinct ways such that these formulations, even if theoretically and empirically equivalent, postulate \textit{different} entities or mechanisms. A well-known example is Newtonian mechanics, which can be formulated postulating either a set of forces modifying the trajectory on material points, a Lagrangian associated to the material point such that the latter follows the trajectory which minimizes the integral of the Lagrangian along the trajectory or a Hamiltonian driving the dynamics of the physical system seen as a point in a phase space, according to Hamilton equations. More specifically, classical \textit{gravity} can be formulated in the Newtonian framework by postulating well-known $1/r^2-$gravitational force, but can also be formulated in the Newton-Cartan geometrical framework without postulating forces but rather describing it as the manifestation of the curvature of an underlying (classical) spacetime \citep[Chapter~1]{Ehlers1973}. This is not a specificity of Newtonian mechanics, but a feature shared by all physical theories. For instance, quantum mechanics acknowledges at least nine different formulations \citep{Styer2002}: Heisenberg's (matrix), Schrödinger's (wavefunction), Feynman's (path integral), Wigner's (phase space), density matrix, second quantization, variational, de Broglie-Bohm's (pilot wave) and Hamilton-Jacobi's. As for General Relativity, it can also be formulated different ways \citep{Goeckeler2011, Krasnov2020, Arnowitt2008}: using tensor calculus on differential manifolds, Cartan geometry on principal fiber bundles, encoding gravitation in torsion instead of in curvature, or deriving fields equations from Lagrangian or even Hamiltonian principles. All these formulations are equivalent in the sense that it is perfectly known how to mathematically pass from one to the other, and have the same empirical success. However, entities that they postulate (forces or Lagrangians, quantum states as vectors or density matrix, spacetime torsion or curvature, and so on) together with fundamental mechanisms and laws which lie at the foundation of their explanatory power have sometimes nothing to do with each other. Picture of reality given by these formulations are thus deeply distinct, even though the latter are epistemologically equivalent and all highly acceptable as explanatory models. 

This observation then highly \textit{suggests} that realisticness of basic hypotheses is finally neither necessary nor relevant a criterion as for the acceptability of theoretical models. This very statement actually ties in with the more general \textit{fictional view} of models, presented in section~\ref{sec:asifVerifJust}. As already written in the introduction, this view nevertheless raises two important questions: an epistemological one (how to justify the use of models if the realisticness of their basic assumptions is not necessary?) and a realism-related one (do such a view condemn us to antirealism?). We tackle these issues in section~\ref{sec:epistemo_criterion} and in section~\ref{sec:asif_realism} respectively.

\section{As-if modelling and reference}
\label{sec:asifVerifJust}

\subsection{Models are fictions, and that's no worry at all}

The central tension at play may be called the \textit{modelling conundrum} and can be stated as follows:

\begin{definition}[Modelling Conundrum (MC)]
    Scientific models play a central role in representing and explaining, and yet they feature idealisations and deliberate falsities.
\end{definition}

MC if often taken as a basis of a critique of truth-oriented positions in various sectors of epistemology and philosophy of science. An obvious example is \textit{naïve scientific realism}: if an empirically adequate and predictively powerful model is interpreted as a faithful description of a phenomenon, then how is it possible to account for its idealised characteristics?

There is therefore a close relationship between the emphasis placed on the ``as-if'' nature of models and antirealist or instrumentalist conceptions of science. Idealisations, simplifications, abstractions or even the introduction of purely fictional entities or mechanisms, possess obvious epistemic virtues (see e.g. \citep{Sullivan2019, Lawler2019, Nawar2019, Pincock2021} for a further discussion of idealisation's epistemic virtues): simplicity, computability, enabling understanding, etc. 

As we showed earlier, the conundrum has less to do with the realisticness of the model's basic assumptions than with the interpretation of its empirical and predictive power. Even in physics, models feature this kind of false, or incompatible with background knowledge, assumptions.\footnote{For example, the billiard ball model of gases describes entities that simply cannot exist in a quantum universe.} Even the concept of physical law considered as \textit{ceteris paribus} generalisation \citep{Cartwright1983} has to do with the idealised status of models: laws are true of the models, not of the messy reality they, at most approximately, represent.

If Moscati's first assumption about ``as-ifness'' of models is inaccurate, we can still make sense of the core of his argument: the as-if nature of modelling is problematic for truth-oriented conceptions of scientific succes.

The problem can now be framed in more specific terms: is it possible to accept Moscati's second claim, namely that as-ifness is not problematic, while resisting antirealist or instrumentalist tendencies? We think the response is positive and the remainder of this paper is intended to defend this claim.

MC is particularly noticeable when adopting the so-called ``fiction-view of models'' \citep{Frigg2016, Frigg2020, Toon2012}. In this perspective, models are conceives as props in a game of make-believe: an agent using a model of some target system, be it physical, social or economical, is engaging in a game of make-believe by accepting a set of hypotheses for the sake of manipulating the model, i.e. deriving new fictional propositions (propositions true inside the fiction) from known ones. This framework is interesting because it makes clear the distinction between what is true inside the model and what is possibly true outside, i.e. in what the model portrays. Engaging in a game of make-believe involves accepting some knowingly false assumptions only for the sake of the game: no ontological weight is attached to them.

That explains the coexistence of incompatible hypotheses or models, as in the case of semi-classical models in physics. A physicist manipulating the billiard ball model in order to work out the temperature or pressure of a perfect gas using the well-known equation $PV=nRT$ is not committed to the claim that molecules bounce off each other. The important aspect of the fiction view is then to highlight the epistemic role of idealisations while keeping a distinction between what the model describes literally and what are the conclusions the user might want to infer to the target.

Therefore, we see that the critique of economical as-if models as faithful representations of target systems and mechanisms rely on a inaccurate understanding of the status of idealisations and knowingly false assumptions in modelling. The latter have epistemic virtues and explanatory power (see Section \ref{sec:expla} hereunder for a further discussion of the explanatory power of fictional models), but they do not reduce the models to predictive tools. Of course, that does not mean that antirealism and the fiction view cannot go hand in hand. Indeed, it is easy to see what a position like that would look like: the comparison between scientific models and fictions leadsto the conclusion that models are nothing but fictions, that is things that can be more or less useful for certain goals, but certainly not true or adequate in any sense.

{\color{red}{(Mettre une citation de Vaihinger ? Tu penses que ça peut être utile ?)}}

Regarding as-if modelling, and keeping in mind the content of MC, we can now better understand Moscati's proposal of being agnostic about ``whether this mechanism actually operates in the mind of the decision maker''. \citep[p.~2]{Moscati2023}

This attitude is exactly what the make-believe view of modelling puts forward: an agent might want to use the assumption that such and such mechanism operates in the mind of the decision maker while not believing it does, just as a reader might engage in a novel without believing a school of magic does exist. All the reasons we have to believe that these assumptions are not realistic (because they are not compatible with what is known of human psychology, for example) do not change anything to the kind of game the modeller is playing when using the model. Trying to save the realisticness of these hypotheses by assuming they are not conscious in the mind of the decision maker simply shifts the problem. As Moscati puts himself about these model-mechanisms: ``it is more appropriate to acknowledge that they take place in the conscious mind of the decision theorist.'' \citep[p.~12]{Moscati2023}

The tension between realist and antirealist positions regarding (MC) is then to be found in the process of justification of the models. If a model is ({\color{red}{in, e.g., Vaihinger's perspective}}) only assessable in terms of (epistemic) utility, if no external justification canbe found, then it provides an argument in favour of antirealism.

Our goal in the remainder of this paper is to show that the fictional context may as well be used to defend a realist position by providing a truth-riented justification of the models.


\subsection{Realism and as-ifness: good friends after all?}

As we have seen, the realist challenge is not about interpreting psychologically the functions that appear in the economical models. With this regard, they are perfectly acceptable as they are: fictional statements true only in the model and not applicable to the target systems, i.e. human agents in a specified economical system.

The realist challenge rather concerns the possibility of establishing independent means of justification of the model. To understand the very nature of the problem, let us take a closer look at Moscati's flavour of antirealism. As he defines it \citep[pp.~18-20]{Moscati2023}, following the three-fold definition of \citep{Psillos1999}, he:

\begin{itemize}
    \item Accepts the metaphysical thesis according to which there is a mind-independent reality which is the object of scientific inquiry;
    \item Accepts the semantic thesis about observable, but remains sceptical about unobservable (expliquer ce que ça veut dire plus en détail parce que je pense qu'on a un point de désaccord là-dessus. Faut qu'on en parle);
    \item Accepts the epistemological thesis about observables, models are true descriptions of the observable, while being sceptical about unobservable entities and mechanism that produce the observed behaviour.
\end{itemize}

As he himself notes, this position is a classical form of instrumentalism, the only difference is that Moscati also defends a variant of mechanistic explanation that goes beyond traditional instrumentalism For that reason, we have refrained from using the qualifier ``instrumentalist'' for his position. We will specifically address the explanation problem in Section \ref{sec:expla}.

There is no particular worry concerning the metaphysical thesis, whereas both the semantic and epistemic need to be further discussed.

First, concerning semantic realism, Moscati defines it in terms of \textit{literal representations}:

\begin{quote}
    According to semantic realism, scientific terms should provide literal representations of the observable and unobservable entities they refer to, although also approximate representations, such as abstractions or idealizations, are admitted. \citep[p.~18]{Moscati2023}
\end{quote}

Stated in these terms, it becomes clear that the as-if interpretation of modelling carries a antirealist understanding of the situation: models, as support of a game of \textit{make-believe}, are non-committal by nature about the entities it portrays. However, it could be argued that this use of the semantic thesis is quite inadequate for its purpose. The core of the semantic thesis is not the approximate validity of the representations provided by the model, but the fact that models provide representations. The term ``literal'' means that models or theories are descriptions of matters of facts, representations of phenomena. One of the most discussed antirealist position is the constructive empiricism proposed by van Fraassen \citep{vanFraassen1980}, and he is quite clear about his acceptance of the semantic thesis: theories (or models) are interpreted literally in the sense of being considered as representations, while remaining agnostic about the existence of the referents. That is, when a model describes such and such entity to such and such mechanism, the semantic realist considers that the meaning of the model, what the model tells us about reality, is that such and such entities behave like it is portrayed, with no regard for the representation's adequacy. Accepting the semantical thesis does not imply any commitment about the existence of the depicted entities.

{\color{red}{Mettre une citation de vF pour appuyer notre point et mettre Moscati encore plus dans la sauce ?}}

In his definition, Moscati includes approximations and idealisations. Why so? Interpreted litterally, a model does not portray anything as an idealisation: it is the user of the model that plays the game of make-believe. It is true in the perfect gas model that molecules bounce off each other. It is only when used as a representation of real gases that this assumption acquires the status of an idealisation. In fact, Moscati's semantical thesis already incorporates an instrumentalist flavour, as it makes impossible any justification that goes beyond the fictional status of the content of the model. The meaning of the model is already defined in terms of approximation, and then there is no hope for verification. But how can we know that something is an approximation if no prior verification has been made (or, at least, if the modeller does not have an a priori idea of what he is modelling)?

{\color{red}{Fun fact : alors que j'écris ces lignes, une chanson au pif se lance\dots et elle s'appelle ``not that well defined''. No joke.}}

Being a literal description is a necessary condition of being an adequate description, the latter question being the core of the epistemological thesis that states empirical adequacy and predictive power as signs of truth of the model qua description of a state of facts. In other words, empirical success and (at least partial) truth are related in some way. The critique of realism performed by Moscati attacks the possibility of justifying such a relation.

Let us push the fictional analogy a step forward, and let us try to rephrase Moscati's argument in this perspective. Models tell us stories about entities behaving in a variety of ways. Engaging in the modelling activity is akin to playing a game of make-believe: accepting idealised assumptions, deriving new fictional truths, exploring the world of the model. The semantic thesis states that the sroty told by the model is actually a story about real physical systems, that is, models are not instruments judged on their predictive power and empirical adequacy, they tell stories about facts, and they are therefore capable of being true or false. The epistemological thesis states that empirical adequequacy is a good guide to truth.

Moscati's definitions are unable to keep the two aspects of realism separate, and that leads him to jump too quickly to an antirealist conclusion. We hope that the fiction view has helped clarify those matters.


\section{``Unrealistic'' assumptions as substrates of modelling and classification principles}
\label{sec:epistemo_criterion}

From a fictional view of modelling developed in section~\ref{sec:asifVerifJust}, it turns out that some basic assumptions does not have to be taken too literally, as really describing what is going on beyond direct observations, but rather as mere \textit{substrates of modelling}. That is to say, as hypotheses which are necessary to take but which are not genuine empirical statements. Take a metro map as an illustrative example. A metro map can be seen as a model of the real metro network, a lot of features of which are highly idealized or even literally wrong, as the form of the lines between metro stations. However, if the purpose is to be able to move from a station to another one, it would be silly not to trust such a map for the reason that it contains idealisations or ``false assumptions'' about the form of the lines between stations. Our point is not that empirical false statements do not matter in general, but rather that these assumptions are simply not empirical statements. The form of the lines between stations has to be represented in some ways for the map to exist, but they are not claiming anything about the lines between stations as they really are out there. Indeed, this is simply not the purpose of the map and it is assumed that the form of the lines does not impinge on this purpose. Likewise metro lines have to be represented having a certain form (for instance, as straight lines), agents in rational choice, behavioral or heuristic models have to be represented computing information in some way in order to reproduce the observed behaviors. However, there is no reason for this representation to be realistic, i.e. consistent with what is otherwise known about human behavior, as long as the model reaches the purpose for which it is built. 

We thus agree with Moscati on the point that any model (in general, but in particular in decision theory) is as-if, and that it is not a fundamental epistemological issue. As for the epistemological criteria of acceptability of a given model, here is the account that Moscati gives from his antirealist perspective  \citep[p.~22]{Moscati2023}: 

\begin{quote}
Insofar as a decision mechanism produces, i.e. explains, the targeted choice-behaviour phenomena in a simple and parcimonious way, and insofar as the decision theory incorporating the mechanism is successful \textelp{} in describing, predicting or controlling the targeted choice-behaviour phenomena, the explanation provided by the mechanism is a valid one.
\end{quote}

We obviously agree that classical epistemological criteria as simplicity, parsimony or predictive capacity are good criteria in general and in the case of mechanisms-based explanations in particular. However, we would like to go a bit further and build up a an epistemological criterion dealing explicitly with the issue of false assumptions in the modelling process and possibly realist-compatible. We now introduce this ``structural invariance'' criterion, as developed by one author in more details in \citep{attard_rationality}. Later on, it will be argued that this criterion is able to take into account all features of as-if modelling issues as described above while possibly being justified from a realist perspective.

The construction of the criterion starts with the following observation: the non triviality of an explanation of the form $\{\mathrm{fundamental~principles + specific~hypotheses}\}$ as described above in equation \eqref{eq:pattern_expl} rests on the constraints which are imposed to the set of specific hypotheses used in a given empirical context. More precisely, if acting rationally only means maximizing a utility function, then given any behavior, it is always possible to find a utility function to maximize, under the form of \textit{ad hoc} hypotheses. Besides, this is a classical criticism of the (careless) use of rationality in the social science, as expressed e.g by P. Ylikoski and P. Hedström in \citep[Chapter~2,~pp.~59-60]{Manzo2014}:
\begin{quote}
From the point of view of the core assumptions of [rational choice theory (RCT)], broadening the range of individuals’ concerns to non-monetary goods and to the welfare of others is straightforward, although there is concern about whether this can be done in a non-arbitrary manner. \textelp{} Finding a RCT model that fits a particular phenomenon becomes almost trivially easy as there are no real constraints on preferences and beliefs that can be attributed to the individuals in question.
\end{quote}

Thus, relevant epistemological criteria do not apply directly to the fundamental principles or the specific hypotheses \textit{per se}, e.g. demanding their accuracy, realisticness or external consistency, but rather to the set of constraints which are imposed to the specific hypotheses in order to turn \eqref{eq:pattern_expl} into a non trivial explanation within a given set of fundamental principles. In physics, what makes a specific hypothesis (for example, $1/r^2$--gravitational term in Newtonian physics) epistemologically acceptable is not that it is realistic or merely true (for reasons cited above), but rather that it is \textit{systematically} associated to a certain set of empirical situations (here, some gravitational phenomena) with great empirical success (non trivial adequacy), and that in other formulations of classical mechanics it has a corresponding term which is also systematically associated to the same set of empirical situations with the same empirical success. Thus, the constraints imposed to the set of acceptable theoretical hypotheses ends up exhibiting a certain \textit{structure}: a systematic association between classes of phenomena and classes of models which explain them. The final point is that even if general principles and theoretical hypotheses can be formulated in different ways, they provide isomorphic classifications of models and thus a classification of phenomena which does not depend on any particular formulation. 

There is no obvious reason for this observation to be restricted to physics: on the contrary, we claim that it is a quite fundamental epistemological feature. As long as the logical pattern of explanation looks like \eqref{eq:pattern_expl}, the question has to be addressed of how to render the explanation non trivial -- more precisely, what constraints apply on the specific hypotheses used to instantiate the given set of fundamental principles. Meanwhile, any explanatory model often enjoys several equivalent formulations which are either incompatible to each other or not necessarily coherent with what is otherwise known. Our point is that relevant epistemological criteria apply to the set of constraints bearing on the specific hypotheses used in the explanatory model in the following manner: a set of fundamental principles derives its epistemological value from the extent to which it allows a salient (i.e. not trivial) classification of empirical facts within classes of models (corresponding to specific finite sets of theoretical hypotheses) which explain them, such that this classification does not depend, at the end, on any particular formulation. Again, from our viewpoint we should not take fundamental principles or hypotheses too literally, as really describing what is going on beyond direct observations, but as a (necessary) representation of an underlying classification principle. ``Realisticness'' of these assumptions is thus not the relevant epistemological criterion at work: their role is only to concretely embody this classification, not to represent reality. 

That is why basic assumptions in decision theory models do not need to be realistic, or consistent with what is known about human behavior. Taking rational choice models as an example, what really counts is not whether agents are really computing complicated utility functions in their mind, because this, from our viewpoint, is not an empirical question. Indeed, such basic assumptions in theoretical models are not, despite their form, genuine empirical statements but only a way of embodying a certain classification principle which is the actual empirical proposal to be tested. From our structural invariance perspective, what really matters is rather what types of utilities are taken into account in the optimization process, and whether these types of utilities are already used in other similar contexts -- in order for an invariant structure to be eventually highlighted. 

Thus, embracing a fictional view of models does not imply arbitrariness in modelling choices -- which is of course acknowledged even by antirealists. We nevertheless constructed an epistemological criterion of model selection which explicitely takes into account the fact that models contain falsities or idealisations. In the next section, as announced, we argue that fictionalism does not necessarily rime with antirealism neither, and bring the discussion at a realism-related level. We also argue that the realist view developed then is fully compatible with the structural invariance criterion presented in the present section, and that both developments actually strengthen each other.

\section{As-if modelling, justification and realism}
\label{sec:asif_realism}

The second part of the realist challenge stated in preceding sections consists in the construction of independent empirically based justification of the model.

More specifically, we consider a response to be realist if it accepts the semantical and epistemological theses. As already mentioned, Moscati accepts both for observables, but also denies both regarding unobservables, in particular for the mechanisms postulated by the models.

Of course, in a fictional perspective, being realist about these mechanisms and some (if not all) the entities in concerns and involves is a no-go: they are knowingly unrealistic. The effectiveness of the $PV=nRT$ equation is certainly not a proof that molecules are bouncing spheres, neither the utility RCT of is a proof that agents are non-stopping-utility-maximisators.

What, then, can be taken as the basis of justification of the model?  We argue that the fiction view pulls towards a counterfactual view of justification and explanation. We adress both in the remainder of this and in the next section, respectively.

The fiction view portrays scientific models as set of propositions deriving from some hypotheses and principles. Playing the game of \textit{make-believe} is accepting idealised hypotheses in order to derive new fictional truths, with the hope the latter are applicable to the target system (i.e. the model supports inferences to the target). Let us call these propositions the agent using the model is willing to apply to the target system model-world propositions.

What is the nature of model-world propositions? From a formal point of view, they are conclusions of a deductive process starting from fictional hypotheses. In other words, model-world propositions are counterfactual propositions. The example from the perfect gas law speaks for itself. Any proposition about a real gas, which is supposed to be sufficiently similar to a perfect gas for the inference to be reliable, derives from a set of hypotheses in which we find at least one idealised assumption. When making a prediction about the pressure or the temperature of the modelled gas, the complete form of the proposition is something like ``if the perfect gas law is true, then this gas will behave as such and such'' In fact, the very application of the perfect gas law to a phenomenon carries with it the idealised assumption that lies behind. Model-world propositions then take the form of an implication where at least one of the antecedents is false, and that is one of the reasons why many epistemologists defend a modal view of modelling (see e.g. \citep{VerreaultJulien2019}): the very counterfactual nature of model-world propositions can only produce possibility claims.

So far so good, but an important question stays unsolved: are model-world propositions immune to the fictional process of modelling? Indeed, the modelling conundrum we are interested in is still problematic. Even if we accept not to reject the possibility of justifying the model in a way that is compatible with the traditional theses of realism from the observation that its basic assumptions are knowingly false, the question is still begging for model-world propositions. In other words, if the only claims a scientific model is able to provide are possibility claims, then how can we hope to empirically justify them?












\section{Realism and explanation veritism}

\section{Conclusion}

\bibliography{biblio} 
\bibliographystyle{plainnat}
\end{document}
